{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Youtube API v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "import urllib.parse as p\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "SCOPES = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL               = \"URL\"\n",
    "KIND_OF_VIDEO     = \"kind\"\n",
    "_ID               = \"id\"\n",
    "PUBLISHED_AT      = \"publishedAT\"\n",
    "CHANNEL_TITLE     = \"channelTitle\"\n",
    "VIDEO_TITLE       = \"videoTitle\"\n",
    "DESCRTIPTION      = \"description\"\n",
    "LIKE_COUNT        = 'likeCount'\n",
    "VIEW_COUNT        = \"viewCount\"\n",
    "COMMENT_COUNT     = \"commentCount\"\n",
    "TAGS              = \"tags\"\n",
    "DURATION          = \"duration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_authenticate():\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"credentials.json\"\n",
    "    creds = None\n",
    "    # the file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first time\n",
    "    if os.path.exists(\"token.pickle\"):\n",
    "        with open(\"token.pickle\", \"rb\") as token:\n",
    "            creds = pickle.load(token)\n",
    "    # if there are no (valid) credentials availablle, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # save the credentials for the next run\n",
    "        with open(\"token.pickle\", \"wb\") as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    return build(api_service_name, api_version, credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_id_by_url(url):\n",
    "    \"\"\"\n",
    "    Return the Video ID from the video `url`\n",
    "    \"\"\"\n",
    "    # split URL parts\n",
    "    parsed_url = p.urlparse(url)\n",
    "    # get the video ID by parsing the query of the URL\n",
    "    video_id = p.parse_qs(parsed_url.query).get(\"v\")\n",
    "    if video_id:\n",
    "        return video_id[0]\n",
    "    else:\n",
    "        raise Exception(f\"Wasn't able to parse video URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, **kwargs):\n",
    "    return youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        **kwargs\n",
    "    ).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_infos(video_response,video_url):\n",
    "    items = video_response.get(\"items\")[0]\n",
    "    snippet         = items[\"snippet\"]\n",
    "    statistics      = items[\"statistics\"]\n",
    "    content_details = items[\"contentDetails\"]\n",
    "\n",
    "    kindOfVideo   = items[\"kind\"]\n",
    "    vid_id        = items[\"id\"]\n",
    "    publish_time  = snippet[\"publishedAt\"]\n",
    "    channel_title = snippet[\"channelTitle\"]\n",
    "    title         = snippet[\"title\"]\n",
    "    description   = snippet[\"description\"]\n",
    "    view_count    = statistics[\"viewCount\"]\n",
    "    like_count    = statistics[\"likeCount\"]\n",
    "    comment_count = statistics[\"commentCount\"]\n",
    "    duration      = content_details[\"duration\"]\n",
    "    tags          = snippet[\"tags\"]\n",
    "    videoData = {URL:video_url,\n",
    "                KIND_OF_VIDEO  :kindOfVideo,\n",
    "                 _ID           :vid_id,\n",
    "                 PUBLISHED_AT  :publish_time,\n",
    "                 CHANNEL_TITLE :channel_title,\n",
    "                 VIDEO_TITLE   :title,\n",
    "                 DESCRTIPTION  :description,\n",
    "                 VIEW_COUNT    :view_count,\n",
    "                 LIKE_COUNT    :like_count,\n",
    "                 COMMENT_COUNT :comment_count,\n",
    "                 TAGS          :tags,\n",
    "                 DURATION      :duration                 \n",
    "                }\n",
    "    \n",
    "    return(videoData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrapeVideoByURL(video_url):\n",
    "    # parse video ID from URL\n",
    "    video_id = get_video_id_by_url(video_url)\n",
    "    # make API call to get video info\n",
    "    response = get_video_details(youtube, id=video_id)\n",
    "    # print extracted video infos\n",
    "    \n",
    "    return(get_video_infos(response,video_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfURLS(filename):\n",
    "    listofURLS = []\n",
    "    file = open(filename)\n",
    "    text_list = file.readlines()\n",
    "    l = len(text_list)\n",
    "    for i in range(0,l):\n",
    "        listofURLS.append(text_list[i].rstrip())\n",
    "    file.close()\n",
    "    return(listofURLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSVfromListURLs(listname,resultpath):\n",
    "    df = pd.DataFrame()\n",
    "    for videoURL in getListOfURLS(listname):\n",
    "        df = df.append(scrapeVideoByURL(videoURL),ignore_index=True)\n",
    "    df.to_csv(resultpath, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate to YouTube API\n",
    "youtube = youtube_authenticate()\n",
    "#Data Extraction\n",
    "getCSVfromListURLs(\"ARTECHListOfURLs.csv\",r\"C:\\\\Users\\\\Ahmid\\\\YoutubeProject\\\\data_artech.csv\")\n",
    "getCSVfromListURLs(\"AHWListOfURLs.csv\",r\"C:\\\\Users\\\\Ahmid\\\\YoutubeProject\\\\data_ahw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform and Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artech = pd.read_csv(\"data_artech.csv\")\n",
    "df_ahw = pd.read_csv(\"data_ahw.csv\")\n",
    "df = pd.concat([df_artech, df_ahw])\n",
    "df.to_csv(\"data.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlEngine       = create_engine('mysql+pymysql://root:@127.0.0.1/yt_db', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "try:\n",
    "\n",
    "    frame = df.to_sql(\"myyt\", dbConnection, if_exists='fail');\n",
    "\n",
    "except ValueError as vx:\n",
    "\n",
    "    print(vx)\n",
    "\n",
    "except Exception as ex:   \n",
    "\n",
    "    print(ex)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Table created successfully.\");   \n",
    "\n",
    "finally:\n",
    "\n",
    "    dbConnection.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
